{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>tafid</th>\n",
       "      <th>station</th>\n",
       "      <th>airport</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>elevationmeters</th>\n",
       "      <th>remarks</th>\n",
       "      <th>bulletintimeutc</th>\n",
       "      <th>issuetimeutc</th>\n",
       "      <th>validtimefromutc</th>\n",
       "      <th>validtimetoutc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3907097</td>\n",
       "      <td>LRIA</td>\n",
       "      <td>IAS</td>\n",
       "      <td>47.17</td>\n",
       "      <td>27.62</td>\n",
       "      <td>104</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2013/O9-07 08:00:OO+00</td>\n",
       "      <td>2O13-O9-07 18:00:0O+00</td>\n",
       "      <td>2O13-09/07 09:00:0O+00</td>\n",
       "      <td>2013-O9-07 18:00:00+OO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3906430</td>\n",
       "      <td>EFKU</td>\n",
       "      <td>KUO</td>\n",
       "      <td>63.02</td>\n",
       "      <td>27.8</td>\n",
       "      <td>102</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2O13-09-O7 O5:00:00+00</td>\n",
       "      <td>2013/09-O8 06:00:0O+00</td>\n",
       "      <td>2013-O9-07 O6:0O:00+00</td>\n",
       "      <td>2013-09-08 O6:00:0O+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>3605075</td>\n",
       "      <td>ESNU</td>\n",
       "      <td>UME</td>\n",
       "      <td>63.78</td>\n",
       "      <td>20.27</td>\n",
       "      <td>14</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2O13/08/14 20:O0:00+0O</td>\n",
       "      <td>2013-08-15 06:00:O0+00</td>\n",
       "      <td>2013-O8-14 21:0O:0O+O0</td>\n",
       "      <td>2O13-O8-15 06:0O:O0+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3606043</td>\n",
       "      <td>YPTN</td>\n",
       "      <td>KTR</td>\n",
       "      <td>-14.43</td>\n",
       "      <td>132.27</td>\n",
       "      <td>109</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2013/O8-14 23:00:00+0O</td>\n",
       "      <td>2013-08-16 OO:00:00+00</td>\n",
       "      <td>2013-08-15 OO:0O:00+00</td>\n",
       "      <td>2013-08-16 O0:00:00+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>3607244</td>\n",
       "      <td>EFMA</td>\n",
       "      <td>MHQ</td>\n",
       "      <td>60.12</td>\n",
       "      <td>19.88</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2013-08-14 23:00:00+00</td>\n",
       "      <td>2O13-08-15 09:00:00+00</td>\n",
       "      <td>2O13-08-15 00:OO:00+00</td>\n",
       "      <td>2013-O8-15 09:00:00+0O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0    tafid station airport  latitude longitude elevationmeters  \\\n",
       "0           0  3907097    LRIA     IAS     47.17     27.62             104   \n",
       "1           1  3906430    EFKU     KUO     63.02      27.8             102   \n",
       "2           2  3605075    ESNU     UME     63.78     20.27              14   \n",
       "3           3  3606043    YPTN     KTR    -14.43    132.27             109   \n",
       "4           4  3607244    EFMA     MHQ     60.12     19.88               6   \n",
       "\n",
       "  remarks         bulletintimeutc            issuetimeutc  \\\n",
       "0     NaN  2013/O9-07 08:00:OO+00  2O13-O9-07 18:00:0O+00   \n",
       "1     NaN  2O13-09-O7 O5:00:00+00  2013/09-O8 06:00:0O+00   \n",
       "2     NaN  2O13/08/14 20:O0:00+0O  2013-08-15 06:00:O0+00   \n",
       "3     NaN  2013/O8-14 23:00:00+0O  2013-08-16 OO:00:00+00   \n",
       "4     NaN  2013-08-14 23:00:00+00  2O13-08-15 09:00:00+00   \n",
       "\n",
       "         validtimefromutc          validtimetoutc  \n",
       "0  2O13-09/07 09:00:0O+00  2013-O9-07 18:00:00+OO  \n",
       "1  2013-O9-07 O6:0O:00+00  2013-09-08 O6:00:0O+00  \n",
       "2  2013-O8-14 21:0O:0O+O0  2O13-O8-15 06:0O:O0+00  \n",
       "3  2013-08-15 OO:0O:00+00  2013-08-16 O0:00:00+00  \n",
       "4  2O13-08-15 00:OO:00+00  2013-O8-15 09:00:00+0O  "
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('C:\\\\Users\\\\Mehika\\\\OneDrive\\\\Documents\\\\Semester 3\\\\DataHack 3.0\\\\data science dataset\\\\dirty data 2\\\\training2_taf.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'tafid', 'station', 'airport', 'latitude', 'longitude',\n",
       "       'elevationmeters', 'remarks', 'bulletintimeutc', 'issuetimeutc',\n",
       "       'validtimefromutc', 'validtimetoutc'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(360671, 12)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop_duplicates(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(360571, 12)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mehika\\AppData\\Local\\Temp\\ipykernel_23268\\1479159849.py:1: DtypeWarning: Columns (10) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df1 = pd.read_csv('C:\\\\Users\\\\Mehika\\\\OneDrive\\\\Documents\\\\Semester 3\\\\DataHack 3.0\\\\data science dataset\\\\dirty data 2\\\\training2_tafforecast.csv')\n",
      "C:\\Users\\Mehika\\AppData\\Local\\Temp\\ipykernel_23268\\1479159849.py:3: DtypeWarning: Columns (0) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df3 = pd.read_csv('C:\\\\Users\\\\Mehika\\\\OneDrive\\\\Documents\\\\Semester 3\\\\DataHack 3.0\\\\data science dataset\\\\dirty data 2\\\\training2_tafsky.csv')\n"
     ]
    }
   ],
   "source": [
    "df1 = pd.read_csv('C:\\\\Users\\\\Mehika\\\\OneDrive\\\\Documents\\\\Semester 3\\\\DataHack 3.0\\\\data science dataset\\\\dirty data 2\\\\training2_tafforecast.csv')\n",
    "df2 = pd.read_csv('C:\\\\Users\\\\Mehika\\\\OneDrive\\\\Documents\\\\Semester 3\\\\DataHack 3.0\\\\data science dataset\\\\dirty data 2\\\\training2_taficing.csv')\n",
    "df3 = pd.read_csv('C:\\\\Users\\\\Mehika\\\\OneDrive\\\\Documents\\\\Semester 3\\\\DataHack 3.0\\\\data science dataset\\\\dirty data 2\\\\training2_tafsky.csv')\n",
    "df4 = pd.read_csv('C:\\\\Users\\\\Mehika\\\\OneDrive\\\\Documents\\\\Semester 3\\\\DataHack 3.0\\\\data science dataset\\\\dirty data 2\\\\training2_taftemperature.csv')\n",
    "df5 = pd.read_csv('C:\\\\Users\\\\Mehika\\\\OneDrive\\\\Documents\\\\Semester 3\\\\DataHack 3.0\\\\data science dataset\\\\dirty data 2\\\\training2_tafturbulence.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.drop_duplicates(inplace = True)\n",
    "df2.drop_duplicates(inplace = True)\n",
    "df3.drop_duplicates(inplace = True)\n",
    "df4.drop_duplicates(inplace = True)\n",
    "df5.drop_duplicates(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Potential primary key columns:\n",
      "['Unnamed: 0', 'tafid']\n"
     ]
    }
   ],
   "source": [
    "unique_counts = df.nunique()\n",
    "potential_keys = unique_counts[unique_counts == len(df)].index.tolist()\n",
    "\n",
    "if potential_keys:\n",
    "    print(\"\\nPotential primary key columns:\")\n",
    "    print(potential_keys)\n",
    "else:\n",
    "    print(\"\\nNo unique columns found that can be considered as primary keys.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "No unique columns found that can be considered as primary keys.\n"
     ]
    }
   ],
   "source": [
    "unique_counts = df1.nunique()\n",
    "potential_keys = unique_counts[unique_counts == len(df1)].index.tolist()\n",
    "\n",
    "if potential_keys:\n",
    "    print(\"\\nPotential primary key columns:\")\n",
    "    print(potential_keys)\n",
    "else:\n",
    "    print(\"\\nNo unique columns found that can be considered as primary keys.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Potential primary key columns:\n",
      "['Unnamed: 0']\n"
     ]
    }
   ],
   "source": [
    "unique_counts = df2.nunique()\n",
    "potential_keys = unique_counts[unique_counts == len(df2)].index.tolist()\n",
    "\n",
    "if potential_keys:\n",
    "    print(\"\\nPotential primary key columns:\")\n",
    "    print(potential_keys)\n",
    "else:\n",
    "    print(\"\\nNo unique columns found that can be considered as primary keys.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Potential primary key columns:\n",
      "['Unnamed: 0']\n"
     ]
    }
   ],
   "source": [
    "unique_counts = df3.nunique()\n",
    "potential_keys = unique_counts[unique_counts == len(df3)].index.tolist()\n",
    "\n",
    "if potential_keys:\n",
    "    print(\"\\nPotential primary key columns:\")\n",
    "    print(potential_keys)\n",
    "else:\n",
    "    print(\"\\nNo unique columns found that can be considered as primary keys.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Potential primary key columns:\n",
      "['Unnamed: 0']\n"
     ]
    }
   ],
   "source": [
    "unique_counts = df4.nunique()\n",
    "potential_keys = unique_counts[unique_counts == len(df4)].index.tolist()\n",
    "\n",
    "if potential_keys:\n",
    "    print(\"\\nPotential primary key columns:\")\n",
    "    print(potential_keys)\n",
    "else:\n",
    "    print(\"\\nNo unique columns found that can be considered as primary keys.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Potential primary key columns:\n",
      "['Unnamed: 0']\n"
     ]
    }
   ],
   "source": [
    "unique_counts = df5.nunique()\n",
    "potential_keys = unique_counts[unique_counts == len(df5)].index.tolist()\n",
    "\n",
    "if potential_keys:\n",
    "    print(\"\\nPotential primary key columns:\")\n",
    "    print(potential_keys)\n",
    "else:\n",
    "    print(\"\\nNo unique columns found that can be considered as primary keys.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'tafforecastid', 'tafid', 'altimiter', 'changeindicator',\n",
       "       'forecasttimefromutc', 'forecasttimetoutc', 'probability',\n",
       "       'timebecomingutc', 'verticalvisibility', 'visibilitystatutemiles',\n",
       "       'windspeedknots', 'winddirectiondegrees', 'windgustspeedknots',\n",
       "       'windsheardirectiondegrees', 'windshearheightfeet',\n",
       "       'windshearspeedknots', 'weatherstring', 'notdecoded'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1['Unnamed: 0'].is_unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0_x</th>\n",
       "      <th>tafid</th>\n",
       "      <th>station</th>\n",
       "      <th>airport</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>elevationmeters</th>\n",
       "      <th>remarks</th>\n",
       "      <th>bulletintimeutc</th>\n",
       "      <th>issuetimeutc</th>\n",
       "      <th>...</th>\n",
       "      <th>verticalvisibility</th>\n",
       "      <th>visibilitystatutemiles</th>\n",
       "      <th>windspeedknots</th>\n",
       "      <th>winddirectiondegrees</th>\n",
       "      <th>windgustspeedknots</th>\n",
       "      <th>windsheardirectiondegrees</th>\n",
       "      <th>windshearheightfeet</th>\n",
       "      <th>windshearspeedknots</th>\n",
       "      <th>weatherstring</th>\n",
       "      <th>notdecoded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3907097</td>\n",
       "      <td>LRIA</td>\n",
       "      <td>IAS</td>\n",
       "      <td>47.17</td>\n",
       "      <td>27.62</td>\n",
       "      <td>104</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2013/O9-07 08:00:OO+00</td>\n",
       "      <td>2O13-O9-07 18:00:0O+00</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.21</td>\n",
       "      <td>12.0</td>\n",
       "      <td>300.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NSW</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3906430</td>\n",
       "      <td>EFKU</td>\n",
       "      <td>KUO</td>\n",
       "      <td>63.02</td>\n",
       "      <td>27.8</td>\n",
       "      <td>102</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2O13-09-O7 O5:00:00+00</td>\n",
       "      <td>2013/09-O8 06:00:0O+00</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.21</td>\n",
       "      <td>5.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NSW</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>3605075</td>\n",
       "      <td>ESNU</td>\n",
       "      <td>UME</td>\n",
       "      <td>63.78</td>\n",
       "      <td>20.27</td>\n",
       "      <td>14</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2O13/08/14 20:O0:00+0O</td>\n",
       "      <td>2013-08-15 06:00:O0+00</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.21</td>\n",
       "      <td>4.0</td>\n",
       "      <td>310.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NSW</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3606043</td>\n",
       "      <td>YPTN</td>\n",
       "      <td>KTR</td>\n",
       "      <td>-14.43</td>\n",
       "      <td>132.27</td>\n",
       "      <td>109</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2013/O8-14 23:00:00+0O</td>\n",
       "      <td>2013-08-16 OO:00:00+00</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.21</td>\n",
       "      <td>8.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>3607244</td>\n",
       "      <td>EFMA</td>\n",
       "      <td>MHQ</td>\n",
       "      <td>60.12</td>\n",
       "      <td>19.88</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2013-08-14 23:00:00+00</td>\n",
       "      <td>2O13-08-15 09:00:00+00</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.21</td>\n",
       "      <td>6.0</td>\n",
       "      <td>310.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0_x    tafid station airport  latitude longitude elevationmeters  \\\n",
       "0             0  3907097    LRIA     IAS     47.17     27.62             104   \n",
       "1             1  3906430    EFKU     KUO     63.02      27.8             102   \n",
       "2             2  3605075    ESNU     UME     63.78     20.27              14   \n",
       "3             3  3606043    YPTN     KTR    -14.43    132.27             109   \n",
       "4             4  3607244    EFMA     MHQ     60.12     19.88               6   \n",
       "\n",
       "  remarks         bulletintimeutc            issuetimeutc  ...  \\\n",
       "0     NaN  2013/O9-07 08:00:OO+00  2O13-O9-07 18:00:0O+00  ...   \n",
       "1     NaN  2O13-09-O7 O5:00:00+00  2013/09-O8 06:00:0O+00  ...   \n",
       "2     NaN  2O13/08/14 20:O0:00+0O  2013-08-15 06:00:O0+00  ...   \n",
       "3     NaN  2013/O8-14 23:00:00+0O  2013-08-16 OO:00:00+00  ...   \n",
       "4     NaN  2013-08-14 23:00:00+00  2O13-08-15 09:00:00+00  ...   \n",
       "\n",
       "  verticalvisibility visibilitystatutemiles  windspeedknots  \\\n",
       "0                NaN                   6.21            12.0   \n",
       "1                NaN                   6.21             5.0   \n",
       "2                NaN                   6.21             4.0   \n",
       "3                NaN                   6.21             8.0   \n",
       "4                NaN                   6.21             6.0   \n",
       "\n",
       "   winddirectiondegrees  windgustspeedknots windsheardirectiondegrees  \\\n",
       "0                 300.0                 NaN                       NaN   \n",
       "1                 200.0                 NaN                       NaN   \n",
       "2                 310.0                 NaN                       NaN   \n",
       "3                  80.0                 NaN                       NaN   \n",
       "4                 310.0                 NaN                       NaN   \n",
       "\n",
       "  windshearheightfeet windshearspeedknots  weatherstring  notdecoded  \n",
       "0                 NaN                 NaN            NSW         NaN  \n",
       "1                 NaN                 NaN            NSW         NaN  \n",
       "2                 NaN                 NaN            NSW         NaN  \n",
       "3                 NaN                 NaN            NaN         NaN  \n",
       "4                 NaN                 NaN            NaN         NaN  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "taf1 = df.merge(df1, on = 'tafid', how='outer')\n",
    "taf1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.drop('Unnamed: 0', axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3.drop('Unnamed: 0', axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4.drop('Unnamed: 0', axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "df5.drop('Unnamed: 0', axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tafforecastid</th>\n",
       "      <th>intensity_x</th>\n",
       "      <th>minimumaltitudefeet_x</th>\n",
       "      <th>maximumaltitudefeet_x</th>\n",
       "      <th>cloudbasefeet</th>\n",
       "      <th>cloudtype</th>\n",
       "      <th>cloudcover</th>\n",
       "      <th>validtimeutc</th>\n",
       "      <th>mintemperaturecelcius</th>\n",
       "      <th>maxtemperaturecelcius</th>\n",
       "      <th>surfacetemperaturecelcius</th>\n",
       "      <th>intensity_y</th>\n",
       "      <th>minimumaltitudefeet_y</th>\n",
       "      <th>maximumaltitudefeet_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12219652</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>800.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>BKN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12219652</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>OVC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12245366</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>800.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>BKN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12245366</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>OVC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12297017</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2500.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SCT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   tafforecastid  intensity_x  minimumaltitudefeet_x  maximumaltitudefeet_x  \\\n",
       "0       12219652          NaN                    NaN                    NaN   \n",
       "1       12219652          NaN                    NaN                    NaN   \n",
       "2       12245366          NaN                    NaN                    NaN   \n",
       "3       12245366          NaN                    NaN                    NaN   \n",
       "4       12297017          NaN                    NaN                    NaN   \n",
       "\n",
       "   cloudbasefeet cloudtype cloudcover validtimeutc  mintemperaturecelcius  \\\n",
       "0          800.0       NaN        BKN          NaN                    NaN   \n",
       "1         2000.0       NaN        OVC          NaN                    NaN   \n",
       "2          800.0       NaN        BKN          NaN                    NaN   \n",
       "3         2000.0       NaN        OVC          NaN                    NaN   \n",
       "4         2500.0       NaN        SCT          NaN                    NaN   \n",
       "\n",
       "   maxtemperaturecelcius  surfacetemperaturecelcius  intensity_y  \\\n",
       "0                    NaN                        NaN          NaN   \n",
       "1                    NaN                        NaN          NaN   \n",
       "2                    NaN                        NaN          NaN   \n",
       "3                    NaN                        NaN          NaN   \n",
       "4                    NaN                        NaN          NaN   \n",
       "\n",
       "   minimumaltitudefeet_y  maximumaltitudefeet_y  \n",
       "0                    NaN                    NaN  \n",
       "1                    NaN                    NaN  \n",
       "2                    NaN                    NaN  \n",
       "3                    NaN                    NaN  \n",
       "4                    NaN                    NaN  "
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "taf2 = df2.merge(df3, on='tafforecastid', how='outer')\n",
    "taf2 = taf2.merge(df4, on='tafforecastid', how='outer')  \n",
    "taf2 = taf2.merge(df5, on='tafforecastid', how='outer')  \n",
    "taf2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1556088, 14)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "taf2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "taf1.to_csv('taf1.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "taf2.to_csv('taf2.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_air1 = pd.read_csv('C:\\\\Users\\\\Mehika\\\\OneDrive\\\\Documents\\\\Semester 3\\\\DataHack 3.0\\\\data science dataset\\\\dirty data 2\\\\training2_airsigmet.csv')\n",
    "df_air2 = pd.read_csv('C:\\\\Users\\\\Mehika\\\\OneDrive\\\\Documents\\\\Semester 3\\\\DataHack 3.0\\\\data science dataset\\\\dirty data 2\\\\training2_airsigmetarea.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1801, 11)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_air1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19131, 5)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_air2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_air1.drop_duplicates(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1801, 11)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_air1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_air2.drop_duplicates(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19031, 5)"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_air2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'airsigmetid', 'timevalidfromutc', 'timevalidtoutc',\n",
       "       'movementdirdegrees', 'movementspeedknots', 'hazardtype',\n",
       "       'hazardseverity', 'airsigmettype', 'altitudeminft', 'altitudemaxft'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_air1.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'airsigmetid', 'latitude', 'longitude', 'ordinal'], dtype='object')"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_air2.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_air1.drop('Unnamed: 0', axis = 1, inplace = True)\n",
    "df_air2.drop('Unnamed: 0', axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1801, 10)"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_air1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19031, 4)"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_air2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Potential primary key columns:\n",
      "['airsigmetid']\n"
     ]
    }
   ],
   "source": [
    "unique_counts = df_air1.nunique()\n",
    "potential_keys = unique_counts[unique_counts == len(df_air1)].index.tolist()\n",
    "\n",
    "if potential_keys:\n",
    "    print(\"\\nPotential primary key columns:\")\n",
    "    print(potential_keys)\n",
    "else:\n",
    "    print(\"\\nNo unique columns found that can be considered as primary keys.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Potential primary key columns:\n",
      "['airsigmetid']\n"
     ]
    }
   ],
   "source": [
    "unique_counts = df_air1.nunique()\n",
    "potential_keys = unique_counts[unique_counts == len(df_air1)].index.tolist()\n",
    "\n",
    "if potential_keys:\n",
    "    print(\"\\nPotential primary key columns:\")\n",
    "    print(potential_keys)\n",
    "else:\n",
    "    print(\"\\nNo unique columns found that can be considered as primary keys.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "air_merged = df_air1.merge(df_air2, on = 'airsigmetid', how='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>airsigmetid</th>\n",
       "      <th>timevalidfromutc</th>\n",
       "      <th>timevalidtoutc</th>\n",
       "      <th>movementdirdegrees</th>\n",
       "      <th>movementspeedknots</th>\n",
       "      <th>hazardtype</th>\n",
       "      <th>hazardseverity</th>\n",
       "      <th>airsigmettype</th>\n",
       "      <th>altitudeminft</th>\n",
       "      <th>altitudemaxft</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>ordinal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>32927</td>\n",
       "      <td>2013-08-17 14:55:OO+O0</td>\n",
       "      <td>2013/08-17 18:55:0O+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CONVECTIVE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>OUTLOOK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>31.2946</td>\n",
       "      <td>-86.9053</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>32927</td>\n",
       "      <td>2013-08-17 14:55:OO+O0</td>\n",
       "      <td>2013/08-17 18:55:0O+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CONVECTIVE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>OUTLOOK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28.0003</td>\n",
       "      <td>-86.6800</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>32927</td>\n",
       "      <td>2013-08-17 14:55:OO+O0</td>\n",
       "      <td>2013/08-17 18:55:0O+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CONVECTIVE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>OUTLOOK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28.2357</td>\n",
       "      <td>-91.1670</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>32927</td>\n",
       "      <td>2013-08-17 14:55:OO+O0</td>\n",
       "      <td>2013/08-17 18:55:0O+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CONVECTIVE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>OUTLOOK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>29.8500</td>\n",
       "      <td>-90.0000</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32927</td>\n",
       "      <td>2013-08-17 14:55:OO+O0</td>\n",
       "      <td>2013/08-17 18:55:0O+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CONVECTIVE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>OUTLOOK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30.7300</td>\n",
       "      <td>-88.3600</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   airsigmetid        timevalidfromutc          timevalidtoutc  \\\n",
       "0        32927  2013-08-17 14:55:OO+O0  2013/08-17 18:55:0O+00   \n",
       "1        32927  2013-08-17 14:55:OO+O0  2013/08-17 18:55:0O+00   \n",
       "2        32927  2013-08-17 14:55:OO+O0  2013/08-17 18:55:0O+00   \n",
       "3        32927  2013-08-17 14:55:OO+O0  2013/08-17 18:55:0O+00   \n",
       "4        32927  2013-08-17 14:55:OO+O0  2013/08-17 18:55:0O+00   \n",
       "\n",
       "   movementdirdegrees  movementspeedknots  hazardtype hazardseverity  \\\n",
       "0                 NaN                 NaN  CONVECTIVE            NaN   \n",
       "1                 NaN                 NaN  CONVECTIVE            NaN   \n",
       "2                 NaN                 NaN  CONVECTIVE            NaN   \n",
       "3                 NaN                 NaN  CONVECTIVE            NaN   \n",
       "4                 NaN                 NaN  CONVECTIVE            NaN   \n",
       "\n",
       "  airsigmettype altitudeminft altitudemaxft  latitude  longitude ordinal  \n",
       "0       OUTLOOK           NaN           NaN   31.2946   -86.9053       0  \n",
       "1       OUTLOOK           NaN           NaN   28.0003   -86.6800       1  \n",
       "2       OUTLOOK           NaN           NaN   28.2357   -91.1670       2  \n",
       "3       OUTLOOK           NaN           NaN   29.8500   -90.0000       3  \n",
       "4       OUTLOOK           NaN           NaN   30.7300   -88.3600       4  "
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "air_merged.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "air_merged.to_csv('air_merged.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
